{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347b58e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting max month...\n",
      "Running asset-level query and writing to parquet file, this may take a while...\n",
      "✅ Asset parquet file exported\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This code updates the asset data\n",
    "\n",
    "'''\n",
    "\n",
    "import duckdb\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Build SQLAlchemy engine for PostgreSQL\n",
    "user = quote_plus(os.getenv(\"CLIMATETRACE_USER\"))\n",
    "password = quote_plus(os.getenv(\"CLIMATETRACE_PASS\"))\n",
    "host = os.getenv(\"CLIMATETRACE_HOST\")\n",
    "port = os.getenv(\"CLIMATETRACE_PORT\")\n",
    "database = os.getenv(\"CLIMATETRACE_DB\")\n",
    "\n",
    "postgres_url = f\"postgresql://{user}:{password}@{host}:{port}/{database}\"\n",
    "parquet_path = \"data/asset_emissions_country_subsector.parquet\"\n",
    "\n",
    "# Use DuckDB to write directly from PostgreSQL to Parquet\n",
    "con = duckdb.connect()\n",
    "\n",
    "\n",
    "print(\"Getting max month...\")\n",
    "max_date = con.execute(f\"\"\"\n",
    "    select max(start_time)\n",
    "    from postgres_scan('{postgres_url}', 'public', 'asset_emissions')                       \n",
    "\"\"\").fetchone()[0]\n",
    "\n",
    "print(\"Running asset-level query and writing to parquet file, this may take a while...\")\n",
    "con.execute(f\"\"\"\n",
    "    INSTALL postgres;\n",
    "    LOAD postgres;\n",
    "\n",
    "    CREATE TABLE asset_emissions_parquet AS\n",
    "    SELECT ae.iso3_country,\n",
    "        ae.original_inventory_sector,\n",
    "        ae.start_time,\n",
    "        ae.gas,\n",
    "        sch.sector,\n",
    "        ca.name as country_name,\n",
    "        ca.continent,\n",
    "        ca.unfccc_annex,\n",
    "        ca.em_finance,\n",
    "        ca.eu,\n",
    "        ca.oecd,\n",
    "        ca.developed_un,\n",
    "        ae.release,\n",
    "        sum(emissions_quantity) emissions_quantity,\n",
    "        sum(activity) activity,\n",
    "        sum(emissions_quantity) / sum(activity) weighted_average_emissions_factor\n",
    "    \n",
    "    FROM postgres_scan('{postgres_url}', 'public', 'asset_emissions') ae\n",
    "    LEFT JOIN postgres_scan('{postgres_url}', 'public', 'country_analysis') ca\n",
    "        ON CAST(ca.iso3_country AS VARCHAR) = CAST(ae.iso3_country AS VARCHAR)\n",
    "    LEFT JOIN (\n",
    "        SELECT DISTINCT sector, subsector FROM postgres_scan('{postgres_url}', 'public', 'asset_schema')\n",
    "    ) sch\n",
    "        ON CAST(sch.subsector AS VARCHAR) = CAST(ae.original_inventory_sector AS VARCHAR)\n",
    "    \n",
    "    WHERE ae.start_time >= (\n",
    "                date_trunc('year', DATE '{max_date}') - INTERVAL '3 YEARS'\n",
    "            )\n",
    "      AND ae.gas = 'co2e_100yr'\n",
    "      AND ae.most_granular = TRUE\n",
    "    \n",
    "    GROUP BY ae.iso3_country,\n",
    "        ae.original_inventory_sector,\n",
    "        ae.start_time,\n",
    "        ae.gas,\n",
    "        sch.sector,\n",
    "        ca.name,\n",
    "        ca.continent,\n",
    "        ca.unfccc_annex,\n",
    "        ca.em_finance,\n",
    "        ca.eu,\n",
    "        ca.oecd,\n",
    "        ca.developed_un,\n",
    "        ae.release;\n",
    "\n",
    "    COPY asset_emissions_parquet TO '{parquet_path}' (FORMAT PARQUET);\n",
    "\"\"\")\n",
    "con.close()\n",
    "\n",
    "print(\"✅ Asset parquet file exported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4f87f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c52d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This is a script to take raw csvs in data/raw_csvs folder and covert them to \n",
    "parquets for manageable GitHub storage and limited memory usage (DuckDB).\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Set input and output directories\n",
    "input_dir = Path(\"data/raw_csvs\")\n",
    "output_dir = Path(\"data\")\n",
    "\n",
    "# Make sure the output directory exists\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Loop through all CSV files in the input directory\n",
    "for csv_file in input_dir.glob(\"*.csv\"):\n",
    "    print(f\"Converting {csv_file.name}...\")\n",
    "\n",
    "    # Read CSV into DataFrame\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Create output path by replacing .csv with .parquet\n",
    "    parquet_file = output_dir / csv_file.with_suffix(\".parquet\").name\n",
    "\n",
    "    # Write to Parquet\n",
    "    df.to_parquet(parquet_file, engine=\"pyarrow\", index=False)\n",
    "    print(f\"Saved to {parquet_file}\")\n",
    "\n",
    "     # Delete original CSV\n",
    "    csv_file.unlink()\n",
    "    print(f\"Deleted original CSV: {csv_file.name}\")\n",
    "\n",
    "print(\"✅ CSV to Parquet conversion complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba171f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_region_condition(region_selection)\n",
    "\n",
    "test = map_region_condition('Asia')\n",
    "\n",
    "print(test)\n",
    "print(test['column_name'])\n",
    "print(test['column_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4186fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "# Replace with your actual path if needed\n",
    "parquet_path = \"data/country_subsector_emissions_totals.parquet\"\n",
    "\n",
    "# Count how many rows you actually wrote\n",
    "result = con.execute(f\"\"\"SELECT sum(emissions_quantity) FROM '{parquet_path}' where start_time = '2025-02-01' and original_inventory_sector not in ('forest-land-clearing',\n",
    "                                                'forest-land-degradation',\n",
    "                                                'forest-land-fires',\n",
    "                                                'net-forest-land',\n",
    "                                                'net-shrubgrass',\n",
    "                                                'net-wetland',\n",
    "                                                'removals',\n",
    "                                                'shrubgrass-fires',\n",
    "                                                'water-reservoirs',\n",
    "                                                'wetland-fires')\"\"\").df()\n",
    "\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f467b0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "# parquet_path = \"data/country_subsector_emissions_totals_202504.parquet\"\n",
    "parquet_path = \"data/asset_emissions_country_subsector.parquet\"\n",
    "\n",
    "result = con.execute(f\"\"\" \n",
    "                     SELECT DISTINCT original_inventory_sector\n",
    "      FROM '{parquet_path}'\n",
    "      WHERE gas = 'co2e_100yr'\n",
    "         AND iso3_country = 'USA'\n",
    "\"\"\"\n",
    ").df()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11551b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "result = con.execute(f\"\"\"\n",
    "                         SELECT \n",
    "        strftime(start_time, '%Y-%m') AS year_month,\n",
    "        SUM(activity) AS activity,\n",
    "        SUM(emissions_quantity) AS emissions_quantity\n",
    "    FROM 'data/test/asset_emissions_country_subsector.parquet'\n",
    "    WHERE gas = 'co2e_100yr' -- AND original_inventory_sector = 'coal-mining'\n",
    "        and original_inventory_sector not in ('forest-land-clearing',\n",
    "                                                'forest-land-degradation',\n",
    "                                                'forest-land-fires',\n",
    "                                                'net-forest-land',\n",
    "                                                'net-shrubgrass',\n",
    "                                                'net-wetland',\n",
    "                                                'removals',\n",
    "                                                'shrubgrass-fires',\n",
    "                                                'water-reservoirs',\n",
    "                                                'wetland-fires')\n",
    "    GROUP BY year_month\n",
    "    ORDER BY year_month\n",
    "                     \"\"\").df()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8f6c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------ Asset Annual Emissions ------------------------------------\n",
    "\n",
    "import duckdb\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Build SQLAlchemy engine for PostgreSQL\n",
    "user = quote_plus(os.getenv(\"CLIMATETRACE_USER\"))\n",
    "password = quote_plus(os.getenv(\"CLIMATETRACE_PASS\"))\n",
    "host = os.getenv(\"CLIMATETRACE_HOST\")\n",
    "port = os.getenv(\"CLIMATETRACE_PORT\")\n",
    "database = os.getenv(\"CLIMATETRACE_DB\")\n",
    "\n",
    "postgres_url = f\"postgresql://{user}:{password}@{host}:{port}/{database}\"\n",
    "parquet_path = \"data/emissions_reduction/asset_annual_emissions.parquet\"\n",
    "\n",
    "# Use DuckDB to write directly from PostgreSQL to Parquet\n",
    "con = duckdb.connect()\n",
    "\n",
    "print('Running query...')\n",
    "con.execute( f'''\n",
    "\tINSTALL postgres;\n",
    "\tLOAD postgres;\n",
    "\n",
    "\tCREATE TABLE asset_annual_emissions_parquet AS\n",
    "\tselect extract(year from ae.start_time) as year\n",
    "\t\t, ae.asset_id\n",
    "\t\t, ai.asset_type\n",
    "\t\t, CASE \n",
    "\t\t\t\tWHEN ae.original_inventory_sector = 'iron-and-steel' AND ai.asset_type LIKE '%BF%' \n",
    "\t\t\t\t\tTHEN '{{''iron-and-steel'': [''BF'', ''DRI-EAF'']}}'\n",
    "\t\t\t\tWHEN ae.original_inventory_sector = 'aluminum' AND ai.asset_type LIKE '%Refinery%' \n",
    "\t\t\t\t\tTHEN '{{''aluminum'': [''Refinery'']}}'\n",
    "\t\t\t\tWHEN ae.original_inventory_sector = 'aluminum' AND ai.asset_type LIKE '%Smelting%' \n",
    "\t\t\t\t\tTHEN '{{''aluminum'': [''Smelting'']}}'\n",
    "\t\t\t\tELSE 'all' \n",
    "\t\t\tEND AS asset_type_2\n",
    "\t\t, ai.asset_name\n",
    "\t\t, ae.iso3_country\n",
    "\t\t, ca.name as country_name\n",
    "        , ca.continent\n",
    "        , ca.eu\n",
    "        , ca.oecd\n",
    "        , ca.unfccc_annex\n",
    "        , ca.developed_un\n",
    "        , ca.em_finance\n",
    "\t\t, asch.sector\n",
    "\t\t, ae.original_inventory_sector as subsector\n",
    "\t\t, al.gadm_1\n",
    "\t\t, al.gadm_2\n",
    "\t\t, al.ghs_fua\n",
    "\t\t, al.city_id\n",
    "\t\t, ae.other1\n",
    "\t\t, ae.other2\n",
    "\t\t, ae.other3\n",
    "\t\t, ae.other4\n",
    "\t\t, ae.other5\n",
    "\t\t, ae.other6\n",
    "\t\t, ae.other7\n",
    "\t\t, ae.other8\n",
    "\t\t, ae.other9\n",
    "\t\t, ae.other10\n",
    "\t\t, ae.activity_units\n",
    "\t\t, sum(capacity) capacity\n",
    "\t\t, sum(activity) activity\n",
    "\t\t, avg(emissions_factor) average_emissions_factor\n",
    "\t\t, sum(emissions_quantity) emissions_quantity\n",
    "\n",
    "\tfrom postgres_scan('{postgres_url}','public', 'asset_emissions') ae\n",
    "\tleft join postgres_scan('{postgres_url}','public', 'asset_information') ai\n",
    "\t\ton ai.asset_id = ae.asset_id\n",
    "\tleft join postgres_scan('{postgres_url}','public', 'asset_location') al\n",
    "\t\ton al.asset_id = ae.asset_id\n",
    "\tleft join (\n",
    "\t\tselect distinct sector, subsector from postgres_scan('{postgres_url}','public', 'asset_schema')\n",
    "\t) asch\n",
    "\t\ton cast(asch.subsector as varchar) = cast(ae.original_inventory_sector as varchar)\n",
    "\tleft join postgres_scan('{postgres_url}','public', 'country_analysis') ca\n",
    "\t\ton cast(ca.iso3_country as varchar) = cast(ae.iso3_country as varchar)\n",
    "\n",
    "\twhere extract(year from ae.start_time) = 2024\n",
    "\t\tand ae.most_granular = true\n",
    "\t\tand ae.gas = 'co2e_100yr'\n",
    "\t\tand ae.original_inventory_sector not in ('forest-land-clearing',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t'forest-land-degradation',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t'forest-land-fires',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t'net-forest-land',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t'net-shrubgrass',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t'net-wetland',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t'removals',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t'shrubgrass-fires',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t'water-reservoirs',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t'wetland-fires')\n",
    "\n",
    "\tgroup by extract(year from ae.start_time)\n",
    "\t\t, ae.asset_id\n",
    "\t\t, ai.asset_type\n",
    "        , CASE \n",
    "\t\t\t\tWHEN ae.original_inventory_sector = 'iron-and-steel' AND ai.asset_type LIKE '%BF%' \n",
    "\t\t\t\t\tTHEN '{{''iron-and-steel'': [''BF'', ''DRI-EAF'']}}'\n",
    "\t\t\t\tWHEN ae.original_inventory_sector = 'aluminum' AND ai.asset_type LIKE '%Refinery%' \n",
    "\t\t\t\t\tTHEN '{{''aluminum'': [''Refinery'']}}'\n",
    "\t\t\t\tWHEN ae.original_inventory_sector = 'aluminum' AND ai.asset_type LIKE '%Smelting%' \n",
    "\t\t\t\t\tTHEN '{{''aluminum'': [''Smelting'']}}'\n",
    "\t\t\t\tELSE 'all' \n",
    "\t\t\tEND\n",
    "\t\t, ai.asset_name\n",
    "\t\t, ae.iso3_country\n",
    "\t\t, ca.name\n",
    "        , ca.continent\n",
    "        , ca.eu\n",
    "        , ca.oecd\n",
    "        , ca.unfccc_annex\n",
    "        , ca.developed_un\n",
    "        , ca.em_finance\n",
    "\t\t, asch.sector\n",
    "\t\t, ae.original_inventory_sector\n",
    "\t\t, al.gadm_1\n",
    "\t\t, al.gadm_2\n",
    "\t\t, al.ghs_fua\n",
    "\t\t, al.city_id\n",
    "\t\t, ae.other1\n",
    "\t\t, ae.other2\n",
    "\t\t, ae.other3\n",
    "\t\t, ae.other4\n",
    "\t\t, ae.other5\n",
    "\t\t, ae.other6\n",
    "\t\t, ae.other7\n",
    "\t\t, ae.other8\n",
    "\t\t, ae.other9\n",
    "\t\t, ae.other10\n",
    "\t\t, ae.activity_units;\n",
    "            \n",
    "    COPY asset_annual_emissions_parquet TO '{parquet_path}' (FORMAT PARQUET);\n",
    "            \n",
    "    ''')\n",
    "\n",
    "con.close()\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295e549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ---------------------------------- ADD MOER FACTORS --------------------------------------\n",
    "\n",
    "# import duckdb\n",
    "from utils.utils import data_add_moer\n",
    "import pandas as pd\n",
    "\n",
    "asset_parquet_path = 'data/emissions_reduction/asset_annual_emissions.parquet'\n",
    "output_path = 'data/emissions_reduction/asset_annual_emissions_moer.parquet'\n",
    "\n",
    "df_asset = pd.read_parquet(asset_parquet_path)\n",
    "\n",
    "asset_moer_df = data_add_moer(df_asset, cond={\"moer\": True})\n",
    "\n",
    "asset_moer_df.to_parquet(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e07028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------ SPLITS LARGE ASSET FILE INTO ~50MB CHUNKS ---------------------------------\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "\n",
    "# === CONFIG ===\n",
    "input_file = \"data/emissions_reduction/asset_annual_emissions_moer.parquet\"  # Your large file\n",
    "output_dir = \"data/asset_annual_emissions\"  # Destination folder\n",
    "target_size_mb = 50  # Keep each file safely under 100MB\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load full Parquet into DataFrame\n",
    "df = pd.read_parquet(input_file)\n",
    "total_rows = len(df)\n",
    "\n",
    "# Estimate file size per row using a small sample\n",
    "test_sample = df.iloc[:10000]\n",
    "test_table = pa.Table.from_pandas(test_sample)\n",
    "pq.write_table(test_table, \"temp.parquet\")\n",
    "bytes_per_row = os.path.getsize(\"temp.parquet\") / len(test_sample)\n",
    "os.remove(\"temp.parquet\")\n",
    "\n",
    "# Determine number of rows per ~50MB chunk\n",
    "target_bytes = target_size_mb * 1024 * 1024\n",
    "rows_per_chunk = int(target_bytes / bytes_per_row)\n",
    "\n",
    "# Split and write files\n",
    "for i, start in enumerate(range(0, total_rows, rows_per_chunk)):\n",
    "    end = min(start + rows_per_chunk, total_rows)\n",
    "    chunk_df = df.iloc[start:end]\n",
    "    chunk_table = pa.Table.from_pandas(chunk_df)\n",
    "    output_path = os.path.join(output_dir, f\"chunk_{i+1}.parquet\")\n",
    "    pq.write_table(chunk_table, output_path)\n",
    "    size_mb = os.path.getsize(output_path) / (1024 * 1024)\n",
    "    print(f\"Saved {output_path} ({size_mb:.1f} MB, rows {start}–{end})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8defd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------------ GADM 1 Emissions ------------------------------------\n",
    "\n",
    "import duckdb\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Build SQLAlchemy engine for PostgreSQL\n",
    "user = quote_plus(os.getenv(\"CLIMATETRACE_USER\"))\n",
    "password = quote_plus(os.getenv(\"CLIMATETRACE_PASS\"))\n",
    "host = os.getenv(\"CLIMATETRACE_HOST\")\n",
    "port = os.getenv(\"CLIMATETRACE_PORT\")\n",
    "database = os.getenv(\"CLIMATETRACE_DB\")\n",
    "\n",
    "postgres_url = f\"postgresql://{user}:{password}@{host}:{port}/{database}\"\n",
    "parquet_path = \"data/emissions_reduction/gadm_1_emissions.parquet\"\n",
    "\n",
    "# Use DuckDB to write directly from PostgreSQL to Parquet\n",
    "con = duckdb.connect()\n",
    "\n",
    "\n",
    "print('Running query')\n",
    "con.execute(f'''\n",
    "    INSTALL postgres;\n",
    "    LOAD postgres;\n",
    "\n",
    "    CREATE TABLE gadm_1_emissions_parquet AS\n",
    "    select extract(year from g1e.start_time) as year \n",
    "        , g1e.gadm_id\n",
    "        , gb.admin_level\n",
    "        , g1e.iso3_country\n",
    "        , ca.name as country_name\n",
    "        , gb.name gadm_1_name\n",
    "        , gb.corrected_name gadm_1_corrected_name\n",
    "        , ca.continent\n",
    "        , ca.eu\n",
    "        , ca.oecd\n",
    "        , ca.unfccc_annex\n",
    "        , ca.developed_un\n",
    "        , ca.em_finance\n",
    "        , asch.sector\n",
    "        , g1e.original_inventory_sector subsector\n",
    "        , g1e.gas\n",
    "        , sum(asset_activity) asset_activity\n",
    "        , sum(asset_emissions) asset_emissions\n",
    "        , sum(remainder_activity) remainder_activity\n",
    "        , sum(remainder_emissions) remainder_emissions\n",
    "        , sum(asset_emissions) + sum(remainder_emissions) as emissions_quantity\n",
    "\n",
    "    from postgres_scan('{postgres_url}', 'public', 'gadm_1_emissions') g1e\n",
    "    inner join (\n",
    "        select distinct gadm_id\n",
    "            , name\n",
    "            , corrected_name\n",
    "            , admin_level\n",
    "        from postgres_scan('{postgres_url}','public', 'gadm_boundaries') \n",
    "        where admin_level = 1\n",
    "    ) as gb\n",
    "        on g1e.gadm_id = gb.gadm_id\n",
    "    left join (\n",
    "        select distinct sector\n",
    "            , subsector\n",
    "        from postgres_scan('{postgres_url}','public', 'asset_schema') \n",
    "    ) asch\n",
    "        on cast(asch.subsector as varchar) = cast(g1e.original_inventory_sector as varchar)\n",
    "    left join postgres_scan('{postgres_url}','public', 'country_analysis') ca\n",
    "\t\ton cast(ca.iso3_country as varchar) = cast(g1e.iso3_country as varchar)\n",
    "\n",
    "    where g1e.gas = 'co2e_100yr'\n",
    "        and extract(year from start_time) = 2024\n",
    "        and g1e.original_inventory_sector not in ('forest-land-clearing',\n",
    "                                                'forest-land-degradation',\n",
    "                                                'forest-land-fires',\n",
    "                                                'net-forest-land',\n",
    "                                                'net-shrubgrass',\n",
    "                                                'net-wetland',\n",
    "                                                'removals',\n",
    "                                                'shrubgrass-fires',\n",
    "                                                'water-reservoirs',\n",
    "                                                'wetland-fires')\n",
    "\n",
    "    group by extract(year from g1e.start_time) \n",
    "        , g1e.gadm_id\n",
    "        , gb.admin_level\n",
    "        , g1e.iso3_country\n",
    "        , ca.name\n",
    "        , gb.name \n",
    "        , gb.corrected_name\n",
    "        , ca.continent\n",
    "        , ca.eu\n",
    "        , ca.oecd\n",
    "        , ca.unfccc_annex\n",
    "        , ca.developed_un\n",
    "        , ca.em_finance\n",
    "        , asch.sector\n",
    "        , g1e.original_inventory_sector\n",
    "        , g1e.gas;\n",
    "\n",
    "    COPY gadm_1_emissions_parquet TO '{parquet_path}' (FORMAT PARQUET);\n",
    "''')\n",
    "con.close()\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04194ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------- GADM 2 BATCH -----------------------------------------------------------------\n",
    "\n",
    "import psycopg2\n",
    "from urllib.parse import quote_plus\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import csv\n",
    "import os\n",
    "\n",
    "user = quote_plus(os.getenv(\"CLIMATETRACE_USER\"))\n",
    "password = quote_plus(os.getenv(\"CLIMATETRACE_PASS\"))\n",
    "host = os.getenv(\"CLIMATETRACE_HOST\")\n",
    "port = os.getenv(\"CLIMATETRACE_PORT\")\n",
    "database = os.getenv(\"CLIMATETRACE_DB\")\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=database,\n",
    "    user=user,\n",
    "    password=password,\n",
    "    host=host,\n",
    "    port=port\n",
    ")\n",
    "\n",
    "cur = conn.cursor(name='parquet_cursor')  # server-side cursor\n",
    "\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "     select extract(year from ge.start_time) as year \n",
    "        , gb1.gadm_id gadm_1_id\n",
    "        , gb1.name gadm_1_name\n",
    "        , gb1.corrected_name gadm_1_corrected_name\n",
    "        , ge.gadm_id gadm_2_id\n",
    "        , gb2.name gadm_2_name\n",
    "        , gb2.corrected_name gadm_2_corrected_name\n",
    "        , gb2.admin_level\n",
    "        , ge.iso3_country\n",
    "        , ca.name as country_name\n",
    "        , ca.continent\n",
    "        , ca.eu\n",
    "        , ca.oecd\n",
    "        , ca.unfccc_annex\n",
    "        , ca.developed_un\n",
    "        , ca.em_finance\n",
    "        , asch.sector\n",
    "        , ge.original_inventory_sector subsector\n",
    "        , sum(asset_activity) asset_activity\n",
    "        , sum(asset_emissions) asset_emissions\n",
    "        , sum(remainder_activity) remainder_activity\n",
    "        , sum(remainder_emissions) remainder_emissions\n",
    "        , sum(asset_emissions) + sum(remainder_emissions) as emissions_quantity\n",
    "\n",
    "    from gadm_emissions ge\n",
    "    inner join (\n",
    "        select distinct gadm_id\n",
    "            , immediate_parent\n",
    "            , name\n",
    "            , corrected_name\n",
    "            , admin_level\n",
    "        from gadm_boundaries\n",
    "        where admin_level = 2\n",
    "    ) as gb2\n",
    "        on ge.gadm_id = gb2.gadm_id\n",
    "    left join (\n",
    "        select distinct sector\n",
    "            , subsector\n",
    "        from asset_schema\n",
    "    ) asch\n",
    "        on cast(asch.subsector as varchar) = cast(ge.original_inventory_sector as varchar)\n",
    "    left join (\n",
    "        select gadm_id\n",
    "            , name\n",
    "            , corrected_name\n",
    "        from gadm_boundaries\n",
    "        where admin_level = 1\n",
    "    ) gb1\n",
    "        on gb1.gadm_id = gb2.immediate_parent\n",
    "    left join country_analysis ca\n",
    "        on cast(ca.iso3_country as varchar) = cast(ge.iso3_country as varchar)\n",
    "\n",
    "    where ge.gas = 'co2e_100yr'\n",
    "        and extract(year from start_time) = 2024\n",
    "        and ge.original_inventory_sector not in ('forest-land-clearing',\n",
    "                                                'forest-land-degradation',\n",
    "                                                'forest-land-fires',\n",
    "                                                'net-forest-land',\n",
    "                                                'net-shrubgrass',\n",
    "                                                'net-wetland',\n",
    "                                                'removals',\n",
    "                                                'shrubgrass-fires',\n",
    "                                                'water-reservoirs',\n",
    "                                                'wetland-fires')\n",
    "\n",
    "    group by extract(year from ge.start_time)\n",
    "        , gb1.gadm_id \n",
    "        , gb1.name\n",
    "        , gb1.corrected_name\n",
    "        , ge.gadm_id \n",
    "        , gb2.name\n",
    "        , gb2.corrected_name\n",
    "        , gb2.admin_level\n",
    "        , ge.iso3_country\n",
    "        , ca.name\n",
    "        , ca.continent\n",
    "        , ca.eu\n",
    "        , ca.oecd\n",
    "        , ca.unfccc_annex\n",
    "        , ca.developed_un\n",
    "        , ca.em_finance\n",
    "        , asch.sector\n",
    "        , ge.original_inventory_sector\n",
    "    \"\"\")\n",
    "\n",
    "# Set up Parquet writer\n",
    "batch_size = 10000\n",
    "output_file = \"data/emissions_reduction/gadm_2_emissions.parquet\"\n",
    "batch_count = 0\n",
    "total_rows = 0\n",
    "\n",
    "print(\"executing gadm_2 query...\")\n",
    "\n",
    "# Fetch first batch\n",
    "rows = cur.fetchmany(batch_size)\n",
    "if not rows:\n",
    "    raise Exception(\"No data returned from query.\")\n",
    "\n",
    "field_names = [desc[0] for desc in cur.description]\n",
    "first_table = pa.Table.from_pylist([dict(zip(field_names, row)) for row in rows])\n",
    "writer = pq.ParquetWriter(output_file, first_table.schema)\n",
    "writer.write_table(first_table)\n",
    "batch_count += 1\n",
    "total_rows += len(rows)\n",
    "print(f\"Processed batch {batch_count} ({len(rows)} rows), total rows: {total_rows}\")\n",
    "\n",
    "# Process remaining batches\n",
    "while True:\n",
    "    rows = cur.fetchmany(batch_size)\n",
    "    if not rows:\n",
    "        break\n",
    "\n",
    "    table = pa.Table.from_pylist([dict(zip(field_names, row)) for row in rows])\n",
    "    table = table.cast(writer.schema)  # ensure schema matches first batch\n",
    "    writer.write_table(table)\n",
    "\n",
    "    batch_count += 1\n",
    "    total_rows += len(rows)\n",
    "    print(f\"Processed batch {batch_count} ({len(rows)} rows), total rows: {total_rows}\")\n",
    "\n",
    "writer.close()\n",
    "cur.close()\n",
    "conn.close()\n",
    "print(\"Export complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c14e646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------ City Emissions ------------------------------------\n",
    "\n",
    "\n",
    "import duckdb\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Build SQLAlchemy engine for PostgreSQL\n",
    "user = quote_plus(os.getenv(\"CLIMATETRACE_USER\"))\n",
    "password = quote_plus(os.getenv(\"CLIMATETRACE_PASS\"))\n",
    "host = os.getenv(\"CLIMATETRACE_HOST\")\n",
    "port = os.getenv(\"CLIMATETRACE_PORT\")\n",
    "database = os.getenv(\"CLIMATETRACE_DB\")\n",
    "\n",
    "postgres_url = f\"postgresql://{user}:{password}@{host}:{port}/{database}\"\n",
    "parquet_path = \"data/emissions_reduction/city_emissions.parquet\"\n",
    "\n",
    "# Use DuckDB to write directly from PostgreSQL to Parquet\n",
    "con = duckdb.connect()\n",
    "\n",
    "print('Running query...')\n",
    "con.execute( f'''\n",
    "\tINSTALL postgres;\n",
    "\tLOAD postgres;\n",
    "\n",
    "\tCREATE TABLE city_emissions_parquet AS\n",
    "    \n",
    "\tselect extract(year from start_time) as year\n",
    "\t\t, ce.city_id\n",
    "\t\t, cb.name as city_name\n",
    "\t\t, cb.corrected_name as corrected_name\n",
    "\t\t, ce.iso3_country\n",
    "\t\t, ca.name as country_name\n",
    "        , ca.continent\n",
    "        , ca.eu\n",
    "        , ca.oecd\n",
    "        , ca.unfccc_annex\n",
    "        , ca.developed_un\n",
    "        , ca.em_finance\n",
    "\t\t, asch.sector\n",
    "\t\t, ce.original_inventory_sector as subsector\n",
    "\t\t, sum(asset_activity) asset_activity\n",
    "\t\t, sum(asset_emissions) asset_emissions\n",
    "\t\t, sum(remainder_activity) remainder_activity\n",
    "\t\t, sum(remainder_emissions) remainder_emissions\n",
    "\t\t, sum(asset_emissions) + sum(remainder_emissions) as emissions_quantity\n",
    "\n",
    "\tfrom postgres_scan('{postgres_url}','public', 'city_emissions') ce\n",
    "\tleft join postgres_scan('{postgres_url}','public', 'city_boundaries') cb\n",
    "\t\ton cb.city_id = ce.city_id\n",
    "\tleft join (\n",
    "\t\tselect distinct sector, subsector\n",
    "\t\tfrom postgres_scan('{postgres_url}','public', 'asset_schema')\n",
    "\t) asch\n",
    "\t\ton cast(asch.subsector as varchar) = cast(ce.original_inventory_sector as varchar)\n",
    "\tleft join postgres_scan('{postgres_url}','public', 'country_analysis') ca\n",
    "\t\ton cast(ca.iso3_country as varchar) = cast(ce.iso3_country as varchar)\n",
    "\n",
    "\twhere extract(year from ce.start_time) = 2024\n",
    "\t\tand ce.gas = 'co2e_100yr'\n",
    "\t\tand ce.original_inventory_sector not in ('forest-land-clearing',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t'forest-land-degradation',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t'forest-land-fires',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t'net-forest-land',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t'net-shrubgrass',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t'net-wetland',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t'removals',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t'shrubgrass-fires',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t'water-reservoirs',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t'wetland-fires')\n",
    "\n",
    "\tgroup by extract(year from start_time) \n",
    "\t\t, ce.city_id\n",
    "\t\t, cb.name \n",
    "\t\t, cb.corrected_name \n",
    "\t\t, ce.iso3_country\n",
    "\t\t, ca.name \n",
    "        , ca.continent\n",
    "        , ca.eu\n",
    "        , ca.oecd\n",
    "        , ca.unfccc_annex\n",
    "        , ca.developed_un\n",
    "        , ca.em_finance\n",
    "\t\t, asch.sector\n",
    "\t\t, ce.original_inventory_sector;\n",
    "            \n",
    "    COPY city_emissions_parquet TO '{parquet_path}' (FORMAT PARQUET);\n",
    "            \n",
    "    ''')\n",
    "\n",
    "con.close()\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d0808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------ GADM 2 Emissions ------------------------------------\n",
    "\n",
    "import duckdb\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Build SQLAlchemy engine for PostgreSQL\n",
    "user = quote_plus(os.getenv(\"CLIMATETRACE_USER\"))\n",
    "password = quote_plus(os.getenv(\"CLIMATETRACE_PASS\"))\n",
    "host = os.getenv(\"CLIMATETRACE_HOST\")\n",
    "port = os.getenv(\"CLIMATETRACE_PORT\")\n",
    "database = os.getenv(\"CLIMATETRACE_DB\")\n",
    "\n",
    "postgres_url = f\"postgresql://{user}:{password}@{host}:{port}/{database}\"\n",
    "parquet_path = \"data/emissions_reduction/gadm_2_emissions.parquet\"\n",
    "\n",
    "# Use DuckDB to write directly from PostgreSQL to Parquet\n",
    "con = duckdb.connect()\n",
    "\n",
    "\n",
    "print('Running query')\n",
    "con.execute(f'''\n",
    "    INSTALL postgres;\n",
    "    LOAD postgres;\n",
    "\n",
    "    CREATE TABLE gadm_2_emissions_parquet AS\n",
    "    select extract(year from ge.start_time) as year \n",
    "        , gb1.gadm_id gadm_1_id\n",
    "        , gb1.name gadm_1_name\n",
    "        , gb1.corrected_name gadm_1_corrected_name\n",
    "        , ge.gadm_id gadm_2_id\n",
    "        , gb2.name gadm_2_name\n",
    "        , gb2.corrected_name gadm_2_corrected_name\n",
    "        , gb2.admin_level\n",
    "        , ge.iso3_country\n",
    "        , ca.name as country_name\n",
    "        , ca.continent\n",
    "        , ca.eu\n",
    "        , ca.oecd\n",
    "        , ca.unfccc_annex\n",
    "        , ca.developed_un\n",
    "        , ca.em_finance\n",
    "        , asch.sector\n",
    "        , ge.original_inventory_sector subsector\n",
    "        , ge.gas\n",
    "        , sum(asset_activity) asset_activity\n",
    "        , sum(asset_emissions) asset_emissions\n",
    "        , sum(remainder_activity) remainder_activity\n",
    "        , sum(remainder_emissions) remainder_emissions\n",
    "        , sum(asset_emissions) + sum(remainder_emissions) as emissions_quantity\n",
    "\n",
    "    from postgres_scan('{postgres_url}','public', 'gadm_emissions') ge\n",
    "    inner join (\n",
    "        select distinct gadm_id\n",
    "            , immediate_parent\n",
    "            , name\n",
    "            , corrected_name\n",
    "            , admin_level\n",
    "        from postgres_scan('{postgres_url}','public', 'gadm_boundaries')\n",
    "        where admin_level = 2\n",
    "    ) as gb2\n",
    "        on ge.gadm_id = gb2.gadm_id\n",
    "    left join (\n",
    "        select distinct sector\n",
    "            , subsector\n",
    "        from postgres_scan('{postgres_url}','public', 'asset_schema')\n",
    "    ) asch\n",
    "        on cast(asch.subsector as varchar) = cast(ge.original_inventory_sector as varchar)\n",
    "    left join (\n",
    "        select gadm_id\n",
    "            , name\n",
    "            , corrected_name\n",
    "        from postgres_scan('{postgres_url}','public', 'gadm_boundaries')\n",
    "        where admin_level = 1\n",
    "    ) gb1\n",
    "        on gb1.gadm_id = gb2.immediate_parent\n",
    "    left join postgres_scan('{postgres_url}','public', 'country_analysis') ca\n",
    "        on cast(ca.iso3_country as varchar) = cast(ge.iso3_country as varchar)\n",
    "\n",
    "    where ge.gas = 'co2e_100yr'\n",
    "        and extract(year from start_time) = 2024\n",
    "        and ge.original_inventory_sector not in ('forest-land-clearing',\n",
    "                                                'forest-land-degradation',\n",
    "                                                'forest-land-fires',\n",
    "                                                'net-forest-land',\n",
    "                                                'net-shrubgrass',\n",
    "                                                'net-wetland',\n",
    "                                                'removals',\n",
    "                                                'shrubgrass-fires',\n",
    "                                                'water-reservoirs',\n",
    "                                                'wetland-fires')\n",
    "\n",
    "    group by extract(year from ge.start_time)\n",
    "        , gb1.gadm_id \n",
    "        , gb1.name\n",
    "        , gb1.corrected_name\n",
    "        , ge.gadm_id \n",
    "        , gb2.name\n",
    "        , gb2.corrected_name\n",
    "        , gb2.admin_level\n",
    "        , ge.iso3_country\n",
    "        , ca.name\n",
    "        , ca.continent\n",
    "        , ca.eu\n",
    "        , ca.oecd\n",
    "        , ca.unfccc_annex\n",
    "        , ca.developed_un\n",
    "        , ca.em_finance\n",
    "        , asch.sector\n",
    "        , ge.original_inventory_sector\n",
    "        , ge.gas;\n",
    "\n",
    "    COPY gadm_2_emissions_parquet TO '{parquet_path}' (FORMAT PARQUET);\n",
    "''')\n",
    "con.close()\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4462d363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------- CITY BATCH -----------------------------------------------------------------\n",
    "\n",
    "import psycopg2\n",
    "from urllib.parse import quote_plus\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "\n",
    "user = quote_plus(os.getenv(\"CLIMATETRACE_USER\"))\n",
    "password = quote_plus(os.getenv(\"CLIMATETRACE_PASS\"))\n",
    "host = os.getenv(\"CLIMATETRACE_HOST\")\n",
    "port = os.getenv(\"CLIMATETRACE_PORT\")\n",
    "database = os.getenv(\"CLIMATETRACE_DB\")\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=database,\n",
    "    user=user,\n",
    "    password=password,\n",
    "    host=host,\n",
    "    port=port\n",
    ")\n",
    "\n",
    "cur = conn.cursor(name='parquet_cursor')  # server-side cursor\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    SELECT extract(year from start_time) AS year,\n",
    "           ce.city_id,\n",
    "           cb.name AS city_name,\n",
    "           cb.corrected_name AS corrected_name,\n",
    "           ce.iso3_country,\n",
    "           ca.name AS country_name,\n",
    "           ca.continent,\n",
    "           ca.eu,\n",
    "           ca.oecd,\n",
    "           ca.unfccc_annex,\n",
    "           ca.developed_un,\n",
    "           ca.em_finance,\n",
    "           asch.sector,\n",
    "           ce.original_inventory_sector AS subsector,\n",
    "           SUM(asset_activity) AS asset_activity,\n",
    "           SUM(asset_emissions) AS asset_emissions,\n",
    "           SUM(remainder_activity) AS remainder_activity,\n",
    "           SUM(remainder_emissions) AS remainder_emissions,\n",
    "           SUM(asset_emissions) + SUM(remainder_emissions) AS emissions_quantity\n",
    "    FROM city_emissions ce\n",
    "    LEFT JOIN city_boundaries cb ON cb.city_id = ce.city_id\n",
    "    LEFT JOIN (\n",
    "        SELECT DISTINCT sector, subsector FROM asset_schema\n",
    "    ) asch ON CAST(asch.subsector AS varchar) = CAST(ce.original_inventory_sector AS varchar)\n",
    "    LEFT JOIN country_analysis ca ON CAST(ca.iso3_country AS varchar) = CAST(ce.iso3_country AS varchar)\n",
    "    WHERE extract(year FROM ce.start_time) = 2024\n",
    "      AND ce.gas = 'co2e_100yr'\n",
    "      AND ce.original_inventory_sector NOT IN (\n",
    "          'forest-land-clearing', 'forest-land-degradation', 'forest-land-fires',\n",
    "          'net-forest-land', 'net-shrubgrass', 'net-wetland', 'removals',\n",
    "          'shrubgrass-fires', 'water-reservoirs', 'wetland-fires'\n",
    "      )\n",
    "    GROUP BY extract(year FROM start_time),\n",
    "             ce.city_id, cb.name, cb.corrected_name,\n",
    "             ce.iso3_country, ca.name, ca.continent, ca.eu, ca.oecd,\n",
    "             ca.unfccc_annex, ca.developed_un, ca.em_finance,\n",
    "             asch.sector, ce.original_inventory_sector\n",
    "\"\"\")\n",
    "\n",
    "# Set up Parquet writer\n",
    "batch_size = 10000\n",
    "output_file = \"data/emissions_reduction/city_emissions.parquet\"\n",
    "batch_count = 0\n",
    "total_rows = 0\n",
    "\n",
    "print(\"executing city query...\")\n",
    "\n",
    "# Fetch first batch\n",
    "rows = cur.fetchmany(batch_size)\n",
    "if not rows:\n",
    "    raise Exception(\"No data returned from query.\")\n",
    "\n",
    "field_names = [desc[0] for desc in cur.description]\n",
    "first_table = pa.Table.from_pylist([dict(zip(field_names, row)) for row in rows])\n",
    "writer = pq.ParquetWriter(output_file, first_table.schema)\n",
    "writer.write_table(first_table)\n",
    "batch_count += 1\n",
    "total_rows += len(rows)\n",
    "print(f\"Processed batch {batch_count} ({len(rows)} rows), total rows: {total_rows}\")\n",
    "\n",
    "# Process remaining batches\n",
    "while True:\n",
    "    rows = cur.fetchmany(batch_size)\n",
    "    if not rows:\n",
    "        break\n",
    "\n",
    "    table = pa.Table.from_pylist([dict(zip(field_names, row)) for row in rows])\n",
    "    table = table.cast(writer.schema)  # ensure schema matches first batch\n",
    "    writer.write_table(table)\n",
    "\n",
    "    batch_count += 1\n",
    "    total_rows += len(rows)\n",
    "    print(f\"Processed batch {batch_count} ({len(rows)} rows), total rows: {total_rows}\")\n",
    "\n",
    "writer.close()\n",
    "cur.close()\n",
    "conn.close()\n",
    "print(\"Export complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01348880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()\n",
    "asset_annual_path = 'data/asset_annual_emissions/chunk_*.parquet'\n",
    "output_path = 'data/fixed_aluminum_moer.parquet'\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "                    copy(\n",
    "                        select year\n",
    "                            , asset_id\n",
    "                            , asset_type\n",
    "                            , asset_name\n",
    "                            , iso3_country\n",
    "                            , country_name\n",
    "                            , continent\n",
    "                            , eu\n",
    "                            , oecd\n",
    "                            , unfccc_annex\n",
    "                            , developed_un\n",
    "                            , em_finance\n",
    "                            , sector\n",
    "                            , subsector\n",
    "                            , gadm_1\n",
    "                            , gadm_2\n",
    "                            , ghs_fua\n",
    "                            , city_id\n",
    "                            , other1\n",
    "                            , other2\n",
    "                            , other3\n",
    "                            , other4\n",
    "                            , other5\n",
    "                            , other6\n",
    "                            , other7\n",
    "                            , other8\n",
    "                            , other9\n",
    "                            , other10\n",
    "                            , activity_units\n",
    "                            , capacity\n",
    "                            , activity\n",
    "                            , average_emissions_factor\n",
    "                            , emissions_quantity\n",
    "                            , case when subsector = 'aluminum' then null else ae.ef_moer end as ef_moer\n",
    "                            , case when subsector = 'aluminum' then null else ae.eq_12 end as eq_12\n",
    "                            , case when subsector = 'aluminum' then null else ae.ef_12 end as ef_12\n",
    "                            , case when subsector = 'aluminum' then null else ae.eq_12_moer end as eq_12_moer\n",
    "                            , case when ae.subsector = 'aluminum' then null else ef_12_moer end as ef_12_moer\n",
    "                            , asset_type_2\n",
    "                        \n",
    "                        from '{asset_annual_path}' ae\n",
    "                    ) to '{output_path}' (format 'parquet');\n",
    "                \"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0111db4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "path = 'data/asset_annual_emissions/*.parquet'\n",
    "\n",
    "result = con.execute(f\"\"\"\n",
    "                     select sector\n",
    "                        , sum(emissions_quantity) scope_1\n",
    "                        , sum(activity * coalesce(ef_12_moer, 0)) as scope_1_2\n",
    "                     \n",
    "                     from '{path}' \n",
    "\n",
    "                     group by sector\n",
    "                     \n",
    "                     \"\"\").df()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664e0c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "path = 'data/emissions_reduction/fix_gadm_2.parquet'\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "troubleshoot = con.execute(f\"\"\"\n",
    "        select *\n",
    "\n",
    "        from 'data/asset_annual_emissions/*.parquet'\n",
    "                         \n",
    "        where asset_name = 'Zouping, Shandong aluminium plant'\n",
    "\"\"\"\n",
    ").df()\n",
    "\n",
    "troubleshoot.to_csv('troubleshoot_zouping.csv',index=False)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c5b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/emissions_reduction/ct_percentile_40sectors_moer_stat_industrial_20250619.csv\")\n",
    "df.to_parquet(\"data/emissions_reduction/ct_percentile_40sectors_moer_stat_industrial_20250619.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b681cb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "# Connect to DuckDB\n",
    "con = duckdb.connect()\n",
    "\n",
    "# Path to your parquet file\n",
    "parquet_path = 'data/asset_annual_emissions/*.parquet'\n",
    "\n",
    "# Show all columns\n",
    "con.execute(f\"DESCRIBE SELECT * FROM '{parquet_path}'\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c589af52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
